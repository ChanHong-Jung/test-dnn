{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c5d2325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>div.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc818359",
   "metadata": {},
   "source": [
    "# 합성곱 신경망의 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf078d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\.conda\\envs\\py310tf2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ced26f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_model() missing 1 required positional argument: 'filepath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: load_model() missing 1 required positional argument: 'filepath'"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8aabeb",
   "metadata": {},
   "source": [
    "#### \n",
    "05. 인공지능 알고리즘을 사용하여 인지 기능을 구현하고 \n",
    "과정과 결과를 주석으로 처리 후 코드와 결과를 증빙하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05-1. Fashion MNIST 데이터 로드\n",
    "(train_X, train_y), (test_X, test_y) = fashion_mnist.load_data()\n",
    "\n",
    "print('train_X shape:', train_X.shape)\n",
    "print('test_X shape:', test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05-2. 데이터 정규화\n",
    "train_scaled = train_X.reshape(-1, 28, 28, 1) / 255.0  # float type 변경\n",
    "test_scaled = test_X.reshape(-1, 28, 28, 1)  / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_scaled shape:', train_scaled.shape)\n",
    "print('test_scaled shape:', test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6120a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split (\n",
    "        train_scaled, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d19d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_scaled shape:', train_scaled.shape)\n",
    "print('val_scaled shape:', val_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c06bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05-3. 모델 구성\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=3, input_shape=(28, 28, 1), padding=\"same\", use_bias=True, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", use_bias=True, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f963c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file='cnn-architecture.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a585e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05-4. 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"best-cnn-model.h5\")\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288759c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 05-5. 모델 학습, 모델 저장\n",
    "history = model.fit(train_scaled, train_target,epochs=10,\n",
    "                    validation_data=(val_scaled, val_target),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb86c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(history.history[\"loss\"], \"y\", label=\"train_loss\")\n",
    "loss_ax.plot(history.history[\"val_loss\"], \"r\", label=\"val_loss\")\n",
    "loss_ax.set_xlabel(\"epoch\")\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "loss_ax.legend(loc=\"upper left\")\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "acc_ax.plot(history.history[\"accuracy\"], \"b\", label=\"train_acc\")\n",
    "acc_ax.plot(history.history[\"val_accuracy\"], \"g\", label=\"val_acc\")\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "acc_ax.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d17ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 05-6 모델 평가\n",
    "score = model.evaluate(val_scaled, val_target, verbose=1)\n",
    "print('val loss:', score[0])\n",
    "print('val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val loss: 0.2226928323507309\n",
    "val accuracy: 0.9242500066757202\n",
    "    \n",
    "손실 값이 낮고 정확도가 높으므로, 모델이 검증 데이터에 대해서 좋은 성능을 보이고 있습니다. \n",
    "손실 값이 낮다는 것은 모델이 예측과 실제 값 간의 차이가 적다는 의미이며, \n",
    "정확도가 높다는 것은 모델이 많은 데이터를 올바르게 분류했다는 의미입니다.\n",
    "검증 데이터에 대한 손실과 정확도는 학습 중에 설정한 손실 함수와 \n",
    "평가 지표에 따라서도 달라질 수 있습니다. \n",
    "이러한 결과를 통해 모델이 훈련 데이터에 과적합되지 않고, \n",
    "새로운 데이터에 대해서도 일반화될 수 있음을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aabc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot as plt\n",
    "plt.imshow(val_scaled[0].reshape(28, 28), cmap=\"gray_r\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(val_scaled[0:1])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64766b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_scaled, test_y, verbose=1)\n",
    "print('val loss:', score[0])\n",
    "print('val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a550ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb853b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925434c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b247eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val loss: 0.2226928323507309\n",
    "val accuracy: 0.9242500066757202\n",
    "    \n",
    "손실 값이 낮고 정확도가 높으므로, 모델이 검증 데이터에 대해서 좋은 성능을 보이고 있습니다. \n",
    "손실 값이 낮다는 것은 모델이 예측과 실제 값 간의 차이가 적다는 의미이며, \n",
    "정확도가 높다는 것은 모델이 많은 데이터를 올바르게 분류했다는 의미입니다.\n",
    "검증 데이터에 대한 손실과 정확도는 학습 중에 설정한 손실 함수와 \n",
    "평가 지표에 따라서도 달라질 수 있습니다. \n",
    "이러한 결과를 통해 모델이 훈련 데이터에 과적합되지 않고, \n",
    "새로운 데이터에 대해서도 일반화될 수 있음을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb7aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    ".\n",
    "\n",
    "평가 결과:\n",
    "\n",
    "val loss: 0.2226928323507309: 검증 데이터에 대한 손실 (Loss) 값입니다. 이 값은 모델의 예측이 실제 값과 얼마나 차이가 나는지를 나타냅니다. 낮을수록 좋습니다.\n",
    "val accuracy: 0.9242500066757202: 검증 데이터에 대한 정확도 값입니다. 모델이 검증 데이터에서 얼마나 정확한 예측을 수행했는지를 나타냅니다. 높을수록 좋습니다.\n",
    "해석:\n",
    "\n",
    "손실 값이 낮고 정확도가 높으므로, 모델이 검증 데이터에 대해서 좋은 성능을 보이고 있습니다. 손실 값이 낮다는 것은 모델이 예측과 실제 값 간의 차이가 적다는 의미이며, 정확도가 높다는 것은 모델이 많은 데이터를 올바르게 분류했다는 의미입니다.\n",
    "검증 데이터에 대한 손실과 정확도는 학습 중에 설정한 손실 함수와 평가 지표에 따라서도 달라질 수 있습니다. 여기서는 sparse_categorical_crossentropy 손실 함수와 정확도 지표를 사용한 것으로 가정하겠습니다.\n",
    "이러한 결과를 통해 모델이 훈련 데이터에 과적합되지 않고, 새로운 데이터에 대해서도 일반화될 수 있음을 확인할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19a93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 너비 조정을 위한 스타일 설정\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>div.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# 필요한 라이브러리 및 모듈 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# 저장된 모델 불러오기 (모델 경로 필요)\n",
    "model = tf.keras.models.load_model('your_model_path.h5')\n",
    "\n",
    "# Fashion MNIST 데이터 로드\n",
    "(train_X, train_y), (test_X, test_y) = fashion_mnist.load_data()\n",
    "\n",
    "# 데이터의 형태 확인\n",
    "print('train_X shape:', train_X.shape)\n",
    "print('test_X shape:', test_X.shape)\n",
    "\n",
    "# 데이터 정규화 및 형태 확인\n",
    "train_scaled = train_X.reshape(-1, 28, 28, 1) / 255.0\n",
    "test_scaled = test_X.reshape(-1, 28, 28, 1)  / 255.0\n",
    "print('train_scaled shape:', train_scaled.shape)\n",
    "print('test_scaled shape:', test_scaled.shape)\n",
    "\n",
    "# 데이터를 학습 데이터와 검증 데이터로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split (\n",
    "    train_scaled, train_y, test_size=0.2, random_state=42)\n",
    "print('train_scaled shape:', train_scaled.shape)\n",
    "print('val_scaled shape:', val_scaled.shape)\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, input_shape=(28, 28, 1), padding=\"same\", use_bias=True, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", use_bias=True, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# 모델 구조 출력\n",
    "model.summary()\n",
    "\n",
    "# 모델 구조 시각화\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file='cnn-architecture.png', dpi=100)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "# 모델 체크포인트와 조기 종료 콜백 설정\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"best-cnn-model.h5\")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True) \n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(train_scaled, train_target, epochs=10,\n",
    "                    validation_data=(val_scaled, val_target),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb] )\n",
    "\n",
    "# 학습 과정 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(history.history[\"loss\"], \"y\", label=\"train_loss\")\n",
    "loss_ax.plot(history.history[\"val_loss\"], \"r\", label=\"val_loss\")\n",
    "loss_ax.set_xlabel(\"epoch\")\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "loss_ax.legend(loc=\"upper left\")\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "acc_ax.plot(history.history[\"accuracy\"], \"b\", label=\"train_acc\")\n",
    "acc_ax.plot(history.history[\"val_accuracy\"], \"g\", label=\"val_acc\")\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "acc_ax.legend(loc=\"lower left\")\n",
    "\n",
    "# 모델 평가 및 결과 출력\n",
    "score = model.evaluate(val_scaled, val_target, verbose=1)\n",
    "print('val loss:', score[0])\n",
    "print('val accuracy:', score[1])\n",
    "\n",
    "# 검증 데이터 중 첫 번째 이미지 시각화\n",
    "plt.imshow(val_scaled[0].reshape(28, 28), cmap=\"gray_r\") \n",
    "plt.show()\n",
    "\n",
    "# 모델에 대한 첫 번째 검증 데이터 예측\n",
    "pred = model.predict(val_scaled[0:1])\n",
    "print(pred)\n",
    "\n",
    "# 테스트 데이터에 대한 평가 및 결과 출력\n",
    "score = model.evaluate(test_scaled, test_y, verbose=1)\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Validation Loss (검증 손실): 0.2226928323507309\n",
    "검증 데이터에 대한 손실 값으로, 모델의 예측이 실제 값과 얼마나 차이가 나는지를 나타냅니다.\n",
    "낮은 손실 값은 모델이 검증 데이터에 대해 얼마나 정확한 예측을 수행하는지를 나타냅니다.\n",
    "이 경우, 0.22 정도로 상대적으로 낮은 손실 값은 모델이 검증 데이터에서 좋은 성능을 보이고 있다는 의미입니다.\n",
    "\n",
    "Validation Accuracy (검증 정확도): 0.9242500066757202\n",
    "검증 데이터에 대한 정확도 값으로, 모델이 검증 데이터에서 얼마나 정확하게 분류하는지를 나타냅니다.\n",
    "높은 정확도 값은 모델이 검증 데이터에서 높은 성능을 보이고 있다는 의미입니다.\n",
    "이 경우, 92.42% 정확도는 상당히 좋은 성능으로 평가됩니다.\n",
    "종합적으로, 주어진 결과는 모델이 검증 데이터에 대해 효과적으로 학습되었고, 좋은 성능을 보이고 있다는 것을 나타냅니다. \n",
    "낮은 손실 값과 높은 정확도는 모델이 학습 데이터에 과적합되지 않고, 새로운 데이터에도 잘 일반화되고 있다는 신호입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8ef6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340ecf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
